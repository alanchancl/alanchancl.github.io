---
layout: post
title: 自动驾驶关于对抗攻击的鲁棒性研究
date: 2023-05-31 11:30:17
categories: 论文笔记
tags: AI安全 对抗攻击 自动驾驶
description: 探讨自动驾驶中物理对抗攻击的种类及其对系统安全性的影响，分析不同传感器面临的对抗攻击方法，并提出相应的防御策略。
---

>- 论文名称：[Towards Robust Sensing for Autonomous Vehicles: An adversarial perspective](https://arxiv.org/pdf/2007.10115.pdf)
>- 作者单位：Apostolos Modas / 伦敦玛丽女王大学
>- 收录时间：2020 / IEEE Signal Processing Magazine
>- 文章亮点：总结了自动驾驶中物理对抗攻击的种类，并具体介绍了针对不同传感器的对抗攻击方法、对抗防御方法。

<!--more-->

## 自动驾驶物理对抗攻击——种类

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0" style="text-align: center;">
        {% include figure.liquid path="https://raw.githubusercontent.com/alanchancl/BlogImg/main/img202305311120665.png" title="自动驾驶中的对抗样本" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">自动驾驶中的对抗样本</div>
作者认为自动驾驶中的对抗样本可以分为两类：The **physical** and **on-signal** adversarial attacks

- **physical**  adversarial attacks：物理对抗攻击，通过更改环境导致系统输出错误结果。例如更改光照亮度、修改交通信号牌等
- **on-signal** adversarial attacks：信号对抗攻击，通过更改传感器获取的信号导致系统输出错误结果。

本文将关注于**物理对抗攻击**。物理对抗攻击也可以分为三类：设备、物体和贴纸三种。
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0" style="text-align: center;">
        {% include figure.liquid path="https://raw.githubusercontent.com/alanchancl/BlogImg/main/202306041125321.png" title="物理对抗攻击种类" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>
<div class="caption">物理对抗攻击种类</div>

- 设备：用激光发射器瞄准直接干扰传感器。
- 物体：外形伪造成可以被分类器识别为正常物体的障碍物。
- 贴纸：直接贴在交通信号牌中误导分类器

## 自动驾驶物理对抗攻击——设备篇

本节中讨论使用设备攻击超声波传感器、雷达、GPS、激光雷达和相机的物理对抗方法。

### 1、超声波和雷达传感器
堵塞攻击（jamming attacks）和欺骗攻击（spoofing attacks）可以操纵毫米波雷达和超声波传感器，用于在自动停车或倒车任务中隐藏或添加物体。这些攻击会扰乱传感器的读数，可能导致碰撞事故。这些攻击方法适用于低速移动的车辆，并采用多种技术干扰传感器信号。

- 堵塞攻击：持续发射接近传感器共振频率的超声波，降低信号的信噪比，阻止物体的检测，并在自动停车过程中可能导致碰撞。
- 欺骗攻击：针对雷达传感器，欺骗攻击可以隐藏物体（假阴性）或添加伪物体（假阳性）。隐藏物体：攻击者可以生成接近传感器中心频率的干扰波形，从而阻止检测附近的车辆。添加假物：对抗信号模仿了汽车雷达的信号，但由于估计距离的周期性变化，会导致对伪物体的误认。

### 2、GPS传感器

对GPS传感器的攻击通常旨在用对抗性发射器伪造GNSS传输信号，发射与卫星发送的信号完全相同的信号，从而导致GNSS接收器（即GPS）计算的位置不正确。因为攻击者必须了解GPS接收器和发射器的内部信息，属于白盒攻击。GPS传感器的攻击主要包括欺骗攻击（spoofing attacks）和重放攻击（replay attacks）。

- 欺骗攻击：攻击者首先必须发射足够强大的干扰GNSS信号，使接收器失去对卫星的锁定。然后，攻击者可以伪造并发射与合法GNSS信号相同频率且功率更高的伪造GNSS信号到接收器的天线。如果被攻击接收器对伪造信号的锁定持续存在，那么位置估计就受到攻击者的影响。攻击者可以欺骗不同数量的GPS接收器到任意位置，同时保持它们之间的时间同步。
- 重放攻击：攻击者可以以任意额外延迟重放记录的信号，接收器将在一些特定的信号传播延迟之后开始接收重放的导航消息。而这个延迟可以用于控制接收器对位置、速度、时间（PVT）计算的偏移。随机重放攻击可以在模拟中创建数百公里的位置偏移。

### 3、激光雷达

针对激光雷达的攻击场景可以分为三类：
- front/rear/side：前、后和侧面攻击，指得是靠近自动驾驶车辆的对抗性车辆。
- roadside：路边攻击，在路边安装的恶意设备。
- mechanic：机械攻击，在放置自动驾驶车辆上恶意设备。

根据激光雷达的攻击方法可以分为三类：
- 中继攻击（relay attacks）：在中继攻击中，来自目标车辆的原始信号被从另一个位置中继，以创建虚假回波，并使真实物体的位置看起来更近或更远。
- 欺骗攻击（spoofing attacks）：欺骗攻击创建不存在的物体：原始信号被用作触发器，主动欺骗激光雷达传感器，以中继或重放物体并控制其位置。
- 饱和攻击（saturation attack）：通过用与传感器相同波长的光照射激光雷达来隐藏物体。弱光源会产生随机位置的伪点，而直接照射激光雷达的强光源会完全使传感器或其一部分视野失明。

### 4、相机

有两种攻击方法：
- camera blinding：致盲攻击会对相机传感器照射光线，从而隐藏其视野范围内的任何物体。当相机无法降低自动曝光或增益时，获取的图像就会过曝，发生全盲或部分盲。致盲攻击的有效性取决于环境光、用于致盲的光源（即波长）和敌对光源与相机之间的距离。
- auto control confusion：自动控制混淆攻击，攻击的目标是影响相机的自动曝光控制，攻击者向相机发射光束，在新环境条件稳定下来之前（通常在1至6秒之间），自动驾驶无法检测到物体。攻击者不断开关光源以混淆自动控制，因此，与相机可以更渐进地适应新条件的情况（例如驶出隧道时）不同，该攻击是持续进行的。

## 自动驾驶物理对抗攻击——物体、贴纸篇

### 1、激光雷达的对抗物体：
通过对抗方法可以生成物理3D对抗对象，以误导基于DNN的LIDAR检测系统。为了合成对抗性对象，首先模拟了可微分的激光雷达渲染器；然后，使用可微的代理函数形成特征聚合；最后，通过设计不同的损失函数来确保生成的对抗性对象的平滑性。

### 2、相机的对抗物体：
Expectation OverTransformation（EoT）算法可以用于构建三维物理对抗样本，生成的三维物体即使在改变视角、平移和旋转物体、光照条件、相机噪声和其他物理世界因素时仍然具有对抗性。

### 3、相机的对抗贴纸：
也可以称为对抗补丁，以攻击图像分类或者目标检测任务的相机。

## 自动驾驶物理对抗攻击——防御方法

### 1、超声波和雷达传感器
为了防止攻击和拒绝伪造的回声，通过定制Ping信号和相关性比较来进行物理信号验证。同时，使用超声波传感器和单发射器、多接收器的传感器结构可以实现弹性障碍物检测和攻击者定位。这些方法也可以适用于雷达传感器。

### 2、GPS
对于给定的参数，接收器首先在正常模式下收集数据（训练数据）。然后，基于正常模式数据，接收器预测参数的未来值，并将预测值与从GNSS获得的值进行比较。如果与预测值的差异超过选定的阈值，接收器将判断自身受到攻击，并丢弃所有位置-速度-时间（PVT）解决方案。
还有基于数据比特流变化的攻击检测和基于拍频相位测量的实时欺骗检测。这些机制通过对GNSS数据的分析和处理，以及与预期的模型进行比较，来检测是否存在欺骗攻击，并采取相应的反制措施。

###  3、激光雷达
对于硬件层面，建议使用多个不同波长的LiDAR传感器共同提供扫描信息，并通过跳过发射脉冲或缩短脉冲周期来增加系统的安全性。对于软件层面，提出了在自动驾驶系统、传感器和机器学习模型层面上的防御方法。在自动驾驶层面上，建议过滤地面反射或避免将点云转换为2D矩阵以减少信息丢失。在传感器层面上，建议通过在LiDAR脉冲中引入随机性来增加攻击的难度。在机器学习模型层面上，建议进行对抗性训练以提高系统对抗攻击的能力。

###  4、相机
为了增强深度神经网络对抗性攻击的鲁棒性，对抗性训练是一种有效的方法。然而，它对模型的干净准确性会有一定的负面影响。为了平衡鲁棒性和准确性之间的矛盾，可以在训练损失中添加正则化项来保持决策边界的平滑性。此外，通过一次同时的反向传播来更新模型参数和图像扰动的快速对抗性训练过程可以提高训练效率。对于目标检测任务，通过使用任务导向的对抗性示例，结合不同任务损失之间的相互作用，可以提高对抗性分类准确性和对抗性目标检测准确性。

## 自动驾驶对抗攻击——四大研究方向

### 1、评估方法研究
现有的评估方法通常仅限于特定传感器或机器学习模型，并且使用相似的数据集和架构进行评估。这导致评估的结果有限，因为在一个数据集和架构上有效的攻击可能无法适用于不同配置的模型。为了更全面地评估对抗性攻击的可转移性，需要增加数据集和架构的多样性。此外，目前的评估方法通常在白盒或灰盒设置下进行，这与真实情况不符，因为攻击者可能对底层传感系统或机器学习模型的了解是有限的。为了更好地评估对对抗性扰动的鲁棒性，需要设计在黑盒设置下对物理变换具有不变性的攻击方法。测试各种情况下自动驾驶的鲁棒性。

### 2、融合攻击研究
尽管对单个传感系统的对抗性漏洞进行了深入研究，但对融合信号的研究还相对较少。在对抗性环境中，确定导致错误推断的传感器模态可以为我们提供有关非对抗性传感器如何支持系统并帮助其保持鲁棒性的新见解。通过信号融合实现对抗性鲁棒性可以为我们提供更全面的理解。

### 3、对抗训练研究
对抗性训练主要用于图像分类和目标检测，针对在信号上的对抗性示例。它是一个通用的框架，可用于处理各种类型的对抗性扰动，包括基于补丁的扰动和物理扰动。对抗性训练的原则适用于任何感知模态，只要底层系统是机器学习模型。然而，当前版本的对抗性训练方案可能会陷入某些次优解，这解释了对抗性准确性和标准准确性之间差距的增大。对抗性训练的动态非常重要，需要探索它如何以及为什么改善对抗性鲁棒性。在研究中需要关注对抗性训练的优化过程和效果。

### 4、鲁棒性研究

除了选择强大的攻击方法以避免过度拟合于弱攻击之外，还需要使用无梯度黑盒攻击来测试模型的真实鲁棒性，以确保梯度不仅仅是被混淆的（梯度遮蔽），从而避免给出虚假的鲁棒性感觉。对于存在对抗性扰动的原因，预计是由数据、架构和训练/学习方案等多种因素的组合导致的。对抗性训练通过修改数据和学习方案来实现鲁棒性。在研究架构时，增加模型的容量似乎有助于提高对抗性鲁棒性。未来的研究问题包括其他网络元素（如学习滤波器的大小）对鲁棒性的影响以及所有这些实体之间的相互作用是否导致或防止对抗性漏洞。为了构建和部署更安全的系统，更透明的模型可以解释和解释其功能和推理过程，从而揭示其对抗性漏洞的潜在原因。

## 个人感悟

1、以前对物理对抗样本的理解比较局限，这篇文章提供了很多现实中物理对抗攻击的方法和思路。根据传感器的漏洞或者运行机制进行攻击，本身也是一种强有效的攻击方法。

2、最近想了解一下自动驾驶系统中对抗样本的相关研究，文章虽然不新，但是对我这个新手来说十分有帮助。作者也在最后分享了他认为未来关于自动驾驶鲁棒性研究的四大方向。
