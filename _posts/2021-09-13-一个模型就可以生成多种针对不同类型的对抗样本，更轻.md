---
layout: post
title: 一个模型就可以生成多种针对不同类型的对抗样本，更轻
date: 2021-09-13 15:20:17
description: 本文提出了一种基于条件生成对抗网络(cGAN)的对抗样本生成方法GAP++
categories: 论文笔记
tags: AI安全 对抗攻击
---

>- 论文名称：[《GAP++: Learning to generate target-conditioned adversarial examples》]([[2006.05097v1\] GAP++: Learning to generate target-conditioned adversarial examples (arxiv.org)](https://arxiv.org/abs/2006.05097v1))
>- 作者单位：阿里巴巴研究组
>- 收录时间：2020 CVPR
>- 文章亮点：一个模型就可以生成多种针对不同类型的对抗样本，更轻

<!--more-->

## Motivation

- 当前基于模型的方法存在一下两个问题：

  1. 模型训练耗时长，当攻击类型或攻击目标发生改变时，我们需要对模型进行重新训练。
  2. 基于模型的方法生成的对抗样本具有比较差的可传递性。

- 针对以上的第一个问题，文章使用了条件生成对抗网络（cGAN），并以给定图像和文本去限制输出。使得模型不仅仅可以生成特定目标的干扰，还可以生成以攻击目标为条件的特定图像扰动。

- 简而言之，从一次算一个特定的干扰，变成了一次算多个干扰。因此我此方法仅使用一个训练模型就可以生成所有类型的目标扰动。

- 将非目标攻击转化为有目标攻击，降低训练成本，简化攻击过程。
  
## Method

### 1. Targeted attacks

- 在GAP的基础上进行改进，延续了该方法所生成的对抗样本与输入图像差值不大的特点。
- 对模型的输出进行了归一化，而不是在训练阶段添加客观项。
- 提出了基于模型攻击的新的L0范数，在文章中，L0范数指的是输出扰动△x的前k个像素。（k的值由用户自己决定）
- 最后确保在图像的有效范围内对输出进行裁剪，最终得到了生成的对抗样本。

### 2. Untargeted attacks

- 由于在非目标的情况下不存在目标条件的标签，因此我们在有目标攻击的模型基础上，用零向量来表示无目标攻击模型训练。

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid path="https://raw.githubusercontent.com/alanchancl/BlogImg/main/img202211240902421.png" title="GAP++模型整体结果" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">GAP++模型整体结果</div>

## Experiments

- Dataset: MNIST、CIFAR-10
- 实验说明，本文提出的模型算法，只要一次训练就可以生成多种类型的攻击样本，且均在上述的数据中进行表现良好的攻击。
- 存在缺陷：本文在GAP的基础上提出了改良后的GAP++，其借鉴了原始GAP的网络体系结构和标准化技巧，但比GAP具有更高的性能和更轻的性能。但是其并没有解决基于模型的方法的第二点缺点：可移植性差。